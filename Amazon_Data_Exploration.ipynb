{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744b9eb0",
   "metadata": {},
   "source": [
    " <span style='background:gray;font-size:40px;'>  Setup  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258bd146",
   "metadata": {},
   "source": [
    " <span style='background:gray;font-size:40px;'>  Importing Libraries  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ab2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "#from amazon.api import AMAZONAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3570cf",
   "metadata": {},
   "source": [
    " <span style='background:gray;font-size:40px;'>  Jupyter Options  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c607d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba872ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already running in my instance since I checkboxed Anaconda\n",
    "#%pip install more-itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c44436",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed155393",
   "metadata": {},
   "source": [
    "# Import from Bucket - (Not needed since i uploaded directly onto persistent SSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"finalproject-storage\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# # When you have your files in a subfolder of the bucket.\n",
    "# my_prefix = \"/\" # the name of the subfolder\n",
    "# blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n",
    "\n",
    "# for blob in blobs:\n",
    "#     if(blob.name != my_prefix): # ignoring the subfolder itself \n",
    "#         file_name = blob.name.replace(my_prefix, \"\")\n",
    "#         blob.download_to_filename(file_name) # download the file to the machine\n",
    "#         df = pd.read_csv(file_name) # load the data\n",
    "#         print(df)\n",
    "\n",
    "# When you have your files on the first level of your bucket\n",
    "\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "\n",
    "for blob in blobs:\n",
    "    file_name = blob.name\n",
    "    blob.download_to_filename(file_name) # download the file to the machine\n",
    "    # df = pd.read_csv(file_name) # load the data\n",
    "    # print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Google Cloud Storage client and specify required bucket and file\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket('alouis9')\n",
    "blob = bucket.blob('Electronics_5.json')\n",
    "\n",
    "# Download the contents of the blob as a string and then parse it using json.loads() method\n",
    "#json_data = blob.download_as_string().decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa65606",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.list_blobs()\n",
    "blob\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for blob in blobs:\n",
    "    file_name = blob.name\n",
    "    blob.download_to_filename(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e54433",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gs://alouis9/Electronics_5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f9e26",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93adec7f",
   "metadata": {},
   "source": [
    "<span style='background:gray;font-size:40px;'>  View Local Persistent SSD Tmp Folder where datafiles are stored  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "[s for s in os.listdir('/home/derek') if (s.endswith('.csv') | s.endswith('.gz'))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59da03",
   "metadata": {},
   "source": [
    "# Nodes List w Image Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40133c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    path= '/home/derek/meta_Electronics.json.gz'\n",
    "    def parse(path):\n",
    "        g = gzip.open(path, 'rb')\n",
    "        for l in g:\n",
    "            yield json.loads(l)\n",
    "    def getDF(whatev):\n",
    "        i = 0\n",
    "        df = {}\n",
    "        for d in parse(whatev):\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "    dfnodes = getDF(path)\n",
    "    dfnodes = dfnodes[['asin', 'title', 'imageURLHighRes']].explode('imageURLHighRes')\n",
    "    dfnodes = dfnodes.groupby('asin').first().reset_index()\n",
    "\n",
    "    dfnodes.to_csv(path.split('.')[0] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes.head()\n",
    "dfnodes[dfnodes.duplicated('asin')]\n",
    "print(\"{}{:,}{}\".format(\"There are \",dfnodes.asin.count(),\" unique asins w metadata \\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes.head()\n",
    "dfnodes[dfnodes.duplicated('asin')]\n",
    "print(\"{}{:,}{}\".format(\"There are \",dfnodes.asin.count(),\" unique asins w metadata \\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab572b8",
   "metadata": {},
   "source": [
    "\n",
    "<span style='background:red;font-size:40px;'>  Import Ratings Only CSV Data  </span>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ebedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/derek/Electronics.csv'\n",
    "header_list = [\"item\", \"user\", \"rating\", \"timestamp\"]\n",
    "types_dict = {'item': 'string', 'user': 'string', 'rating': float, 'timestamp':'string'}\n",
    "df_ratings = pd.read_csv(path, names=header_list, dtype=types_dict)\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_ratings),\" reviews in this dataset \\n\"))\n",
    "df_ratings.info()\n",
    "df_ratings = df_ratings.merge(dfnodes,how=\"left\", left_on=['item'], right_on=['asin'])#[[\"item\", \"user\", \"rating\", \"timestamp\", \"title\"]]\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281cb0c",
   "metadata": {},
   "source": [
    "\n",
    "<span style='background:green;font-size:40px;'> Metadata Exploration  </span>\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1853c40",
   "metadata": {},
   "source": [
    "<span style='background:green;font-size:40px;'> Rating Frequency Count </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbdc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ratings.style.format('{:,}')\n",
    "ratingsFreq = df_ratings.groupby('rating').count().sort_values(['rating'],ascending=False)\n",
    "ratingsFreq.style.format('{:,}')\n",
    "print(\"{:,}{}{:,}{}\".format(ratingsFreq.item.iloc[0],\" out of \", ratingsFreq.item.sum(), \" total reviews were rated 5 stars \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b01911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingspct = df_ratings.rating.value_counts(normalize=True)\n",
    "print(\"{}{:,.1%}{}\".format(\"\",ratingspct.iloc[0],\" of the reviews were rated 5 stars \\n\"))\n",
    "ratingspct.to_frame().style.format('{:,.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9171f",
   "metadata": {},
   "source": [
    "\n",
    "<span style='background:green;font-size:40px;'> Average Rating Per Product </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.groupby(['title','item'])['rating'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21328378",
   "metadata": {},
   "source": [
    "<span style='background:green;font-size:40px;'> Top 25 Most Reviewed Products </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f91861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_reviews = df_ratings.groupby('item').count()\n",
    "#num_reviews.sort_values(['rating'],ascending=False)\n",
    "df_ratings.groupby(['title','item']).size().sort_values(ascending=False).head(25)#.agg('count')\n",
    "#top100reviewers = rev_prolific.head(100).reset_index().copy()\n",
    "#top100reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17a3f4",
   "metadata": {},
   "source": [
    "<span style='background:green;font-size:40px;'> Top 10 Product with the most reviews per Rating </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ratings.groupby(['rating', 'item']).size().sort_values(ascending=False).nlargest(10)\n",
    "ratagg = df_ratings.groupby(['title','rating', 'item']).agg({'user':'nunique'}).reset_index()\n",
    "ratsort = ratagg.groupby(['rating']).apply(lambda x: x.sort_values(['user'],ascending = False)).reset_index(drop = True)\n",
    "ratsort.groupby(['rating']).head(10).sort_values(['rating', 'user'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a9396",
   "metadata": {},
   "source": [
    "<span style='background:green;font-size:40px;'> Top 25 Most Prolific Reviewers </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8401bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev_prolific = df_ratings.groupby('user').count().sort_values(['rating'],ascending=False)\n",
    "# top100reviewers = rev_prolific.head(100).reset_index().copy()\n",
    "# top100reviewers\n",
    "\n",
    "df_ratings.groupby('user').size().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffedba",
   "metadata": {},
   "source": [
    "# Find The Product with most reviewer agreement for Each Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd14e0",
   "metadata": {},
   "source": [
    " <span style='background:red;font-size:40px;'> Load Category Product-Level Meta Data and create DF </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53234566",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/derek/meta_Electronics.json.gz'\n",
    "metadata = []\n",
    "with gzip.open(path) as f:\n",
    "    for l in f:\n",
    "        metadata.append(json.loads(l.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b298de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list into pandas dataframe\n",
    "df_metadata = pd.DataFrame.from_dict(metadata)\n",
    "print(len(df_metadata))\n",
    "df_metadata.columns\n",
    "len(df_metadata[df_metadata.isna().any(axis=1)]) # Rows with NANS\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metadata)\n",
    "len(metadata)\n",
    "type(df_metadata)\n",
    "len(df_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}{:,}{}\".format(\"There are \",len(metadata),\" products w metadata \\n\"))\n",
    "\n",
    "# first row of the list\n",
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91692eb7",
   "metadata": {},
   "source": [
    " <span style='background:red;font-size:40px;'> Load MASTER Product-Level Meta Data (all categories) and create DF </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd07ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/derek/title_alsobuy_asin_master.csv'\n",
    "col_list = [\"title\", \"asin\"]\n",
    "types_dict = {'title': 'string', 'alsobuy': 'string', 'asin': 'string'}\n",
    "df_masterMETA = pd.read_csv(path, dtype=types_dict, usecols=col_list, skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0001a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}{:,}{}\".format(\"There are \",len(df_masterMETA),\" items in this dataset \\n\"))\n",
    "df_masterMETA.info()\n",
    "#df_masterMETA = df_ratings.merge(dfnodes,how=\"left\", left_on=['item'], right_on=['asin'])#[[\"item\", \"user\", \"rating\", \"timestamp\", \"title\"]]\n",
    "df_masterMETA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e98c3",
   "metadata": {},
   "source": [
    " <span style='background:green;font-size:40px;'>Duplicate ASINS in Metadata Table</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08846ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metadata[df_metadata.duplicated('asin')].head()\n",
    "len(df_metadata[df_metadata.duplicated('asin')])\n",
    "len(df_alsobuys[df_alsobuys.duplicated('asin')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34096d13",
   "metadata": {},
   "source": [
    "<span style='background:green;font-size:40px;'> List of Duplicate asins in metadata</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc805383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "asin_dupes = df_metadata[df_metadata.duplicated('asin')].sort_values(by=['asin']).asin.tolist()\n",
    "\n",
    "len(asin_dupes)\n",
    "\n",
    "asin_dupes[0:10]\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(asin_dupes),\" asins with more than one row \\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ca5af",
   "metadata": {},
   "source": [
    "\n",
    "<span style='background:green;font-size:40px;'>View Actual Duplicate Asins Side by Side in Metadata Table</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = df_alsobuys\n",
    "\n",
    "df_asindupes = pd.concat(g for _, g in df_metadata.groupby('asin') if len(g) > 1)\n",
    "df_asindupes.shape\n",
    "print(\"{}{:,}{}{:,}{}\".format(\"Since there are \",len(asin_dupes),\" asins with more than one row, there are \", len(df_asindupes),\" rows in total \\n\"))\n",
    "df_asindupes.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6bafb",
   "metadata": {},
   "source": [
    "# These are the rows with NAN in Details Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c78e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metadata[df_metadata.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata[df_metadata.asin=='B01NAJ3KQB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436e4b7",
   "metadata": {},
   "source": [
    " <span style='background:red;font-size:40px;'> ***FILTER METADATA DF***</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21369ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata[df_metadata.asin=='B00JHKSMG8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27623797",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06095eb9",
   "metadata": {},
   "source": [
    " <span style='background:orange;font-size:40px;'>Co-purchases Search</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_copurch = len(df_metadata[(df_metadata.also_buy.str.len() == 0) & (df_metadata.also_view.str.len() == 0)])\n",
    "both_copurch = len(df_metadata[(df_metadata.also_buy.str.len() > 0) & (df_metadata.also_view.str.len() > 0)])\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata),\" asins in total in the metadata table \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",no_copurch,\" asins with no also_buys or also_views \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata[df_metadata.also_buy.str.len() == 0]),\" asins with no also_buys \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata[df_metadata.also_view.str.len() == 0]),\" asins with no also_views \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata[df_metadata.also_buy.str.len() > 0]),\" asins with at least one also_buy co-purchase \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata[df_metadata.also_view.str.len() > 0]),\" asins with at least one also_views co-purchase \\n\"))\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",both_copurch,\" asins with at least one of both co-purchase types \\n\"))\n",
    "\n",
    "df_metadata[(df_metadata.also_buy.str.len() > 0) & (df_metadata.also_view.str.len() > 0)].head()\n",
    "df_graph = df_metadata[(df_metadata.also_buy.str.len() > 0) & (df_metadata.also_view.str.len() > 0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683530f",
   "metadata": {},
   "source": [
    "<span style='background:orange;font-size:40px;'>Alternative Methodology to find Alsobuys exist?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_metadata[\"also_buy\"].apply(lambda x: 1 if len(x) == 0 else 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7221b",
   "metadata": {},
   "source": [
    "<span style='background:orange;font-size:40px;'>Build Subset df to eliminate asins with no alsobuys</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alsobuys = df_metadata[df_metadata.also_buy.str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67644cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_alsobuys)\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(df_metadata[df_metadata.also_buy.str.len() > 0]),\" asins with at least one also_buy co-purchase \\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee535de",
   "metadata": {},
   "source": [
    "<span style='background:orange;font-size:70px;'>At this point there is no reason to keep working with the full category metadata set, so we can eliminate any rows with ZERO also-buys</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311cd2d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Turn this flag on to replace full metadata df with subset limited to asins with alsobuys</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = df_alsobuys\n",
    "df_metadata['asin'].str.strip()\n",
    "len(df_metadata)\n",
    "len(df_metadata)==len(df_alsobuys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc48dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d9242",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895a522",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">There are multiple ways to build an edgelist</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e75f5a",
   "metadata": {},
   "source": [
    "# Create Dictionary Form of Co-Purchases by Asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae34e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two different dictionary structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5bbbb",
   "metadata": {},
   "source": [
    "## Dictionary where the keys are ['asin','title', 'also_buy'] and the values are a dictionary with indexed, attrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsodict = df_metadata[['asin','title', 'also_buy']].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283caa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [{0: '0011300000',\n",
    "#   1: '0043396828',\n",
    "#   2: '0060009810',\n",
    "\n",
    "#list(alsodict.values())[:1]\n",
    "\n",
    "# [{0: 'Genuine Geovision 1 Channel 3rd Party NVR IP Software with USB Dongle Onvif PSIA',\n",
    "#   1: 'Books \"Handbook of Astronomical Image Processing\" with CD ROM, 2nd Edition, Hardcover Book by Berry &amp; Burnell',\n",
    "#   2: 'One Hot Summer',\n",
    "#   3: 'Hurray for Hattie Rabbit: Story and pictures (An Early I can read book)',\n",
    "#   4: 'sex.lies.murder.fame.: A Novel',\n",
    "#   5: 'College Physics',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38396c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict where the ASIN is the key and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadf[['asin','title', 'also_buy']].dropindex()\n",
    "meta_df = df_metadata[['asin','title', 'also_buy']].set_index('asin')\n",
    "#meta_dffinal = df_graph[['asin','title', 'also_buy']].set_index('asin')\n",
    "meta_dict = meta_df.to_dict()\n",
    "#meta_dictfinal = meta_dffinal.to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324baf8",
   "metadata": {},
   "source": [
    "## Dict where the keys are ['title', 'also_buy'] and the values are [asin, attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e013b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.head()\n",
    "#list(meta_dict.items())[0:1]\n",
    "meta_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [('title',\n",
    "#   {'0011300000': 'Genuine Geovision 1 Channel 3rd Party NVR IP Software with USB Dongle Onvif PSIA',\n",
    "#    '0043396828': 'Books \"Handbook of Astronomical Image Processing\" with CD ROM, 2nd Edition, Hardcover Book by Berry &amp; Burnell',\n",
    "#    '0060009810': 'One Hot Summer',\n",
    "#    '0060219602': 'Hurray for Hattie Rabbit: Story and pictures (An Early I can read book)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsodict.keys()\n",
    "meta_dict.keys()\n",
    "#meta_dictfinal.keys()\n",
    "type(meta_dict['also_buy'])\n",
    "#len(meta_dictfinal['also_view'])\n",
    "#meta_df\n",
    "#meta_dict['also_buy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bd418",
   "metadata": {},
   "source": [
    "# ASINS Sorted/Ranked by Number of Also_Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ed74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_values_len(dict):\n",
    "    dict_len= {key: len(value) for key, value in dict.items()}\n",
    "    import operator\n",
    "    sorted_key_list = sorted(dict_len.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_dict = [{item[0]: dict[item [0]]} for item in sorted_key_list]\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619c65e",
   "metadata": {},
   "source": [
    "# Sorted Dictionary where key is asin and value is alsobuys list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsobuys_rnk = sort_by_values_len(meta_dict['also_buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042aa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(meta_dict['also_buy'].items(), key=lambda e: len(e))\n",
    "type(alsobuys_rnk)\n",
    "len(alsobuys_rnk)\n",
    "\n",
    "type(alsobuys_rnk[0])\n",
    "len(alsobuys_rnk[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This Dictionary is 2996 rows less which is correct because it has removed the duplicate rows and combined the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef66642",
   "metadata": {},
   "source": [
    "## Verification that the dictionary is ranked and the 100,776th row has no alsobuys (therefore doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see how the dictionary is ranked by the number of alsobuys\n",
    "alsobuys_rnk[1].values()\n",
    "alsobuys_rnk[100775].values()\n",
    "alsobuys_rnk[100776].values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#gph = nx.from_dict_of_dicts(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae978ad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Create an Edge Set Manually</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c72ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alsobuys_rnk[0]['0545105668']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edgeset = set()\n",
    "for i in range(len(alsobuys_rnk)):\n",
    "    for asin in alsobuys_rnk[i]: \n",
    "        for alsobuy in alsobuys_rnk[i][asin]: # For Every Alsobuy in an alsobuy list\n",
    "            edgeset.add(tuple(sorted((asin,alsobuy)))) # changes order of tuples \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56e7d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Create an Edge LIST</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b166b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = []\n",
    "\n",
    "for i in range(len(alsobuys_rnk)):\n",
    "    for asin in alsobuys_rnk[i]:\n",
    "        for alsobuy in alsobuys_rnk[i][asin]:\n",
    "            edgelist.append((asin, alsobuy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4856ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Note that they are of Different Lengths (probably list has duplicates)</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(edgeset)\n",
    "len(edgeset)\n",
    "type(edgelist)\n",
    "len(edgelist)\n",
    "# The edgelist has 61,000 more than the set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2191f0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">When Creating a Set from the List this way, the number of edges is the same</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = set(map(lambda x: tuple(sorted(x)), edgelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res) #Interesting same length as set above\n",
    "res==edgeset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc7633",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">The above is proof that creating the set of edges is accurate and the list is not</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b25fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same number of asins\n",
    "len(meta_dict['also_buy'].keys())\n",
    "len(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134db5c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dd808",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Annabels formula was built using the raw metadata file, not the df, so to make is less expensive I am lobbing off all rows we already know have no alsobuys<br>\n",
    "<br>I already turned on the flag above to make this conversion so I am just reverting the df back to a list\n",
    "<br>Create SUBSET METADATA TO LOWER COMPUTATION COST OF ANNABELS FORMULA</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a051407",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatab = df_metadata.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metadatab)\n",
    "len(metadatab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db18e0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Annabels Edgelist Function</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a506538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "\n",
    "for item1 in metadatab: \n",
    "    for item2 in item1['also_buy']:\n",
    "        if (item1['asin'],item2) and (item2, item1['asin']) not in dict1: \n",
    "            dict1[(item1['asin'],item2)] = 1\n",
    "        elif (item1['asin'], item2) in dict1: \n",
    "            dict1[(item1['asin'],item2)] += 1\n",
    "        elif (item2, item1['asin']) in dict1:\n",
    "            dict1[(item2,item1['asin'])] += 1\n",
    "    list_of_pairs = [(item1['also_buy'][p1], item1['also_buy'][p2]) for p1 in range(len(item1['also_buy'])) for p2 in range(p1+1,len(item1['also_buy']))]\n",
    "    # for every alsobuy\n",
    "    for (item3,item4) in list_of_pairs: \n",
    "        if(item3, item4) and (item4, item3) not in dict1: \n",
    "             dict1[(item3,item4)] = 1\n",
    "        elif (item3,item4) in dict1: \n",
    "            dict1[(item3,item4)] += 1\n",
    "        elif (item4,item3) in dict1: \n",
    "            dict1[(item4,item3)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pairs = [(metadatab[3]['also_buy'][p1], metadatab[3]['also_buy'][p2]) for p1 in range(len(metadatab[3]['also_buy'])) for p2 in range(p1+1,len(metadatab[3]['also_buy']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatab[3]['also_buy']\n",
    "len(list_of_pairs)\n",
    "list_of_pairs\n",
    "\n",
    "# This is not correct, because you have no idea if these list of pairs are bought together, you only know that each one was bought with item1[asin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d825858",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Correct Edgelist Approach w Weights</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "\n",
    "for item1 in metadatab: \n",
    "    for item2 in item1['also_buy']:\n",
    "        if (item1['asin'],item2) and (item2, item1['asin']) not in dict2: \n",
    "            dict2[(item1['asin'],item2)] = 1\n",
    "        elif (item1['asin'], item2) in dict2: \n",
    "            dict2[(item1['asin'],item2)] += 1\n",
    "        elif (item2, item1['asin']) in dict2:\n",
    "            dict2[(item2,item1['asin'])] += 1\n",
    "    list_of_pairs = [(item1['also_buy'][p1], item1['also_buy'][p2]) for p1 in range(len(item1['also_buy'])) for p2 in range(p1+1,len(item1['also_buy']))]\n",
    "    for (item3,item4) in list_of_pairs: \n",
    "#          if(item3, item4) and (item4, item3) not in dict1: \n",
    "#              dict1[(item3,item4)] = 1\n",
    "        if (item3,item4) in dict2: \n",
    "            dict2[(item3,item4)] += 1\n",
    "            break\n",
    "        elif (item4,item3) in dict2: \n",
    "            dict2[(item4,item3)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f94ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this formula we take all the pairs of items in a single also bought list and then check to see if they are already in the edgelist. If they are we increase their weight by 1\n",
    "# This is correct because we are not adding any new edges we are just giving freqently seen alsobought added focus/weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d989364",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Basic Unweighted Edgeweight Approach, identical to networkx and my approach above</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4065d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict3 = {}\n",
    "\n",
    "for item1 in metadatab: \n",
    "    for item2 in item1['also_buy']:\n",
    "        if (item1['asin'],item2) and (item2, item1['asin']) not in dict3: \n",
    "            dict3[(item1['asin'],item2)] = 1\n",
    "        elif (item1['asin'], item2) in dict3: \n",
    "            dict3[(item1['asin'],item2)] += 1\n",
    "        elif (item2, item1['asin']) in dict3:\n",
    "            dict3[(item2,item1['asin'])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66227ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(dict1)\n",
    "len(dict2)\n",
    "len(dict3)\n",
    "\n",
    "#max(dict1.values())\n",
    "max(dict2.values())\n",
    "max(dict3.values())\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "#dict(itertools.islice(dict2.items(), 10))\n",
    "#sorted(dict2.items(), key=lambda x: x[1],reverse=True)\n",
    "\n",
    "# 29319645\n",
    "# 1818275\n",
    "# 1818275\n",
    "# 271\n",
    "# 109\n",
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c611bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(edgeset)\n",
    "neww = pd.DataFrame(dict2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new[\"lookupkey\"] = new[0] + new[1]\n",
    "neww[\"lookupkey\"] = neww[0] + neww[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.head()\n",
    "#new.info()\n",
    "neww.head()\n",
    "#neww.info()\n",
    "new.sort_values(by='lookupkey').head()\n",
    "neww.sort_values(by='lookupkey').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.DataFrame(dict2.keys()))\n",
    "len(pd.DataFrame(edgeset))\n",
    "d2l = pd.DataFrame(dict2.keys()).tolist()\n",
    "esl = pd.DataFrame(edgeset).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f44d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame.from_dict(dict2, index=[0]).head()\n",
    "\n",
    "\n",
    "ddf = pd.DataFrame(dict2.items())#.astype(str)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddfcopy = ddf.sort_values(by=1, ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafbcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddfcopy.head()\n",
    "srctgt = pd.DataFrame(ddfcopy[0].tolist())\n",
    "\n",
    "srctgt[\"lookupkey\"] = srctgt[0] + srctgt[1]\n",
    "dfwkey = srctgt.astype(str).copy()\n",
    "\n",
    "#dfwkey.merge(ddfcopy, how=[''], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddfcopy[ddfcopy[1]==101][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ddfcopy)\n",
    "len(dfwkey)\n",
    "dfwkey.head()\n",
    "dfwkey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12297dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfapp = ddfcopy.append(dfwkey['lookupkey'],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfapp.head()\n",
    "\n",
    "df_weights = pd.concat([ddfcopy, dfwkey['lookupkey']], axis=1)#.astype(str)\n",
    "df_weights.columns = ['idx', 'edge', 'edge_wt', 'lookup']\n",
    "df_weights.head()\n",
    "df_weights.info()\n",
    "len(df_weights)\n",
    "df_weights = df_weights.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weights[df_weights.lookup=='B0000BVYT3B015PRO512']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14594c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B000FBK3QKB014JV57KS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftuples = pd.DataFrame(ddf[0].tolist())\n",
    "type(dftuples)\n",
    "dftuples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d70d2",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\"> Create Edge set using the networkx built-in function</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed957a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g = nx.from_dict_of_lists(meta_dict['also_buy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta_dict['also_buy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1ae17",
   "metadata": {},
   "source": [
    "# It has the same number of edges as our manual edgeliset but different number of nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.size()\n",
    "type(g)\n",
    "len(g)\n",
    "len(g.nodes())\n",
    "# This matches the manual method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(itertools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f459aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(edgeset)\n",
    "set(itertools.islice(edgeset, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asinlist = list(edgeset)\n",
    "len(asinlist)\n",
    "asinlist[0:5]\n",
    "ab_asins = pd.DataFrame(asinlist, columns=['source','target'])\n",
    "len(ab_asins)\n",
    "ab_asins.head()\n",
    "type(edgeset)\n",
    "\n",
    "#df_ratings = df_ratings.merge(dfnodes,how=\"left\", left_on=['item'], right_on=['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These needs to be an innerjoin followed by a left join with drop na, because if either source or node is missing metadata we need to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dccd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwkey.columns = ['source', 'target', 'lookup']\n",
    "len(dfwkey)\n",
    "len(ab_asins)\n",
    "dfwkey.head()\n",
    "ab_asins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1 = dfwkey.merge(df_masterMETA.rename(columns={'title': 'src_title'}), how='inner', left_on=['target'], right_on=['asin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfmerge1)\n",
    "dfmerge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb045d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffin = dfmerge1.merge(df_masterMETA.rename(columns={'title': 'target_title'}), how='left', left_on=['source'], right_on=['asin']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524803fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dffin)\n",
    "dffin[['source', 'target', 'src_title', 'target_title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb87e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffin[\"lookup\"] = dffin[\"source\"] + dffin[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = dffin.copy()\n",
    "dfff = dfff.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "dfff.head()\n",
    "len(dfff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = dfff.merge(df_weights, how='left', on=['lookup'])[['source','target','src_title','target_title', 'lookup', 'edge_wt']].sort_values(by='edge_wt', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c22b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last[df_last.edge_wt.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb0741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35008c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression_opts = dict(method='zip',\n",
    "#                         archive_name='FINALELECTRONICS.csv')  \n",
    "df_last.to_csv('FINALELECTRONICS.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ab_asins.columns\n",
    "alsobuyseries = ab_asins.iloc[:, 0]\n",
    "len(alsobuyseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ab_asins.melt('topic', value_name='key').drop('variable', 1)\n",
    "df_nodeslist = pd.melt(ab_asins, value_vars=['source', 'target'], value_name='asin')\n",
    "len(df_nodeslist)\n",
    "df_nodesfinal = df_nodeslist.drop_duplicates(subset=['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f633502",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nodesfinal)\n",
    "df_nodesfinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgenames = df_nodesfinal.merge(df_masterMETA,how=\"inner\", left_on=['asin'], right_on=['asin'])#[['variable','asin','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_edgenames)\n",
    "df_edgenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d51e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edgenames.pivot(columns='variable')#['asin','title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc42a7a",
   "metadata": {},
   "source": [
    "# This show the number of unique nodes and matches the built in networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(ab_asins[['source', 'target']].values.ravel('K')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ad3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nodeslist.asin.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709af1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes.set_index('asin').merge(alsobuyseries.rename('source'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes.set_index('asin').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "also_buys_diff_cat = ab_asins.merge(dfnodes,how=\"left\", left_on=['target'], right_on=['asin'])[['source','target','asin','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "also_buys_diff_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f764aea",
   "metadata": {},
   "source": [
    "# Number of Also_Buys from an Outside Cateogry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509aa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also_buys_diff_cat[[also_buys_diff_cat.asin.isnan()]].head()\n",
    "\n",
    "also_buys_diff_cat[also_buys_diff_cat['asin'].isnull()].head(5)\n",
    "\n",
    "print(\"{}{:,}{}\".format(\"There are \",len(also_buys_diff_cat[also_buys_diff_cat['asin'].isnull()]),\" asins in our edgelist from an outside category \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb76fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "also_buys_diff_cat[also_buys_diff_cat.source=='B01NAJ3KQB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608439b6",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><p style=\"font-size:30px\">Join in New Nodes</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c2ff54b",
   "metadata": {},
   "source": [
    "# Merge New MetaData into edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8764e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge1 = ab_asins.merge(df_masterMETA.rename(columns={'title': 'target_title'}),how=\"left\", left_on=['target'], right_on=['asin'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0403d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_edge1)\n",
    "df_edge1.head()\n",
    "ab_asins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge2 = ab_asins.merge(df_masterMETA.rename(columns={'title': 'src_title'}),how=\"left\", left_on=['source'], right_on=['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efec7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_edge2)\n",
    "df_edge2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26158a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwtf = df_edge2.merge(df_edge1,how=\"left\", on='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfwtf)\n",
    "dfwtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24439ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea63df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_edge3 = ab_asins.merge(df_masterMETA,how=\"left\", left_on=['source','target'], right_on=['asin'])\n",
    "dfconcat = pd.concat([df_edge1, df_edge2])\n",
    "#df = pd.concat([ab_asins.merge(df_masterMETA,how=\"inner\", left_on=['target'], right_on=['asin']), ab_asins.merge(df_masterMETA,how=\"inner\", left_on=['source'], right_on=['asin'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3264ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hope = dfconcat[dfconcat.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_hope)\n",
    "df_hope.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f1a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5328dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "df_hope = df[df['asin'].notna()]\n",
    "len(df_hope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d001b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hope.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hope[df_hope.asin=='B000CDHQK2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge1.head()\n",
    "df_edge2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7178fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea956aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72810ffc",
   "metadata": {},
   "source": [
    " # I belive this means that it is adding nodes from the alsobuys that don't exist in the metadata table for the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7428fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6238e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c01f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(g.edges(data=True))[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f5ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b76ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bee3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.edges())\n",
    "len(meta_dict['also_buy'])\n",
    "type(nx.to_edgelist(g)[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for d in alsobuys_rnk:\n",
    "#     g = nx.from_dict_of_lists(alsobuys_rnk[0])\n",
    "# g.edges()\n",
    "# type(g)\n",
    "\n",
    "import networkx as nx\n",
    "graphs = []\n",
    "for i in range(len(alsobuys_rnk)):\n",
    "    g = nx.from_dict_of_lists(alsobuys_rnk[i])\n",
    "    graphs.append(g)\n",
    "final_graph = nx.compose_all(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89160f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_graph = nx.compose_all(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_graph.edges())\n",
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07089a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(final_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a527c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "nodes = []\n",
    "for dict in alsobuys_rnk:\n",
    "    for i in dict:\n",
    "        nodes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76968633",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(alsobuys_rnk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(alsobuys_rnk)\n",
    "len(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "for asin in alsobuys_rnk[1]: print(asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in alsobuys_rnk: print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1859b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_edges(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesset = generate_edgesset(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742863a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edgeslist)\n",
    "edgeslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d187ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeslistlist = generate_edgeslist(alsobuys_rnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edgeslistlist)\n",
    "edgeslistlist[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21bf8a",
   "metadata": {},
   "source": [
    "# Function to Create CSV Edgelist of 1 ASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb816a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: If you use 'b' for the mode, you will get a TypeError\n",
    "# under Python3. You can just use 'w' for Python 3\n",
    "\n",
    "with open('edgelist.csv','w') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['name','num'])\n",
    "    for row in edgeslist:\n",
    "        csv_out.writerow(row)\n",
    "\n",
    "    # You can also do csv_out.writerows(data) instead of the for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc720ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alsodict.keys()\n",
    "meta_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69950bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(alsodict)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce84b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alsodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools\n",
    "#more_itertools.take(1, alsodict.items())\n",
    "#{k: alsodict[k] for k in list(alsodict)[:3]}\n",
    "more_itertools.take(3, meta_df.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc125176",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alsodict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alsodict['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alsodict['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42475341",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alsodict['also_buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsobuy_v1 = df[\"also_buy\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad732766",
   "metadata": {},
   "outputs": [],
   "source": [
    "alsobuy_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c8e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6763606",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = '/edgelist.csv'\n",
    "#header_list = [\"asin\", \"also_buy\"]\n",
    "df_edgelist = pd.read_csv(edgelist)\n",
    "df_edgelist.head()\n",
    "len(df_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeslist=set(df_edgelist.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodeslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cbbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edgelist.csv','w') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['name','num'])\n",
    "    for row in edgeslist:\n",
    "        csv_out.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a938ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata[df_metadata.also_buy.str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18c12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Network Graph\n",
    "Gr = nx.Graph()\n",
    "Gr.add_edges_from(edge_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "#Implementing Girvan_Newman \n",
    "girvan_groups = []\n",
    "girvan_communities = girvan_newman(g)\n",
    "for com in next(girvan_communities): \n",
    "    girvan_groups.append(list(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(girvan_groups)\n",
    "girvan_groups\n",
    "girvan_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = []\n",
    "for node in g:\n",
    "    if node in girvan_groups[0]:\n",
    "        color_map.append('blue')\n",
    "    else: \n",
    "        color_map.append('green')  \n",
    "nx.draw(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93017ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_small_world = nx.watts_strogatz_graph(n=100, k = 5, p = 0.4) \n",
    "#n=number of nodes, k=number of nearby links, p = probability of rewiring a link to a far away node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib q\n",
    "nx.draw_random(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos=nx.spring_layout(g)\n",
    "#nx.draw(g,pos,node_color='#A0CBE2',edge_color='#BB0000',width=2,edge_cmap=plt.cm.Blues,with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graph_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8167a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b577eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(gt.draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ea260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import graph_tool as gt\n",
    "import cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt-get install libcairo2-dev\n",
    "#!pip install pycairo \n",
    "!pip install pycairo==1.11.1\n",
    "#!pip uninstall pycairo --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60df0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prop_type(value, key=None):\n",
    "    \"\"\"\n",
    "    Performs typing and value conversion for the graph_tool PropertyMap class.\n",
    "    If a key is provided, it also ensures the key is in a format that can be\n",
    "    used with the PropertyMap. Returns a tuple, (type name, value, key)\n",
    "    \"\"\"\n",
    "    if isinstance(key, unicode):\n",
    "        # Encode the key as ASCII\n",
    "        key = key.encode('ascii', errors='replace')\n",
    "\n",
    "    # Deal with the value\n",
    "    if isinstance(value, bool):\n",
    "        tname = 'bool'\n",
    "\n",
    "    elif isinstance(value, int):\n",
    "        tname = 'float'\n",
    "        value = float(value)\n",
    "\n",
    "    elif isinstance(value, float):\n",
    "        tname = 'float'\n",
    "\n",
    "    elif isinstance(value, unicode):\n",
    "        tname = 'string'\n",
    "        value = value.encode('ascii', errors='replace')\n",
    "\n",
    "    elif isinstance(value, dict):\n",
    "        tname = 'object'\n",
    "\n",
    "    else:\n",
    "        tname = 'string'\n",
    "        value = str(value)\n",
    "\n",
    "    return tname, value, key\n",
    "\n",
    "\n",
    "def nx2gt(nxG):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph to a graph-tool graph.\n",
    "    \"\"\"\n",
    "    # Phase 0: Create a directed or undirected graph-tool Graph\n",
    "    gtG = gt.Graph(directed=nxG.is_directed())\n",
    "\n",
    "    # Add the Graph properties as \"internal properties\"\n",
    "    for key, value in nxG.graph.items():\n",
    "        # Convert the value and key into a type for graph-tool\n",
    "        tname, value, key = get_prop_type(value, key)\n",
    "\n",
    "        prop = gtG.new_graph_property(tname) # Create the PropertyMap\n",
    "        gtG.graph_properties[key] = prop     # Set the PropertyMap\n",
    "        gtG.graph_properties[key] = value    # Set the actual value\n",
    "\n",
    "    # Phase 1: Add the vertex and edge property maps\n",
    "    # Go through all nodes and edges and add seen properties\n",
    "    # Add the node properties first\n",
    "    nprops = set() # cache keys to only add properties once\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Go through all the properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in nprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key  = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_vertex_property(tname) # Create the PropertyMap\n",
    "            gtG.vertex_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            nprops.add(key)\n",
    "\n",
    "    # Also add the node id: in NetworkX a node can be any hashable type, but\n",
    "    # in graph-tool node are defined as indices. So we capture any strings\n",
    "    # in a special PropertyMap called 'id' -- modify as needed!\n",
    "    gtG.vertex_properties['id'] = gtG.new_vertex_property('string')\n",
    "\n",
    "    # Add the edge properties second\n",
    "    eprops = set() # cache keys to only add properties once\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Go through all the edge properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in eprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_edge_property(tname) # Create the PropertyMap\n",
    "            gtG.edge_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            eprops.add(key)\n",
    "\n",
    "    # Phase 2: Actually add all the nodes and vertices with their properties\n",
    "    # Add the nodes\n",
    "    vertices = {} # vertex mapping for tracking edges later\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Create the vertex and annotate for our edges later\n",
    "        v = gtG.add_vertex()\n",
    "        vertices[node] = v\n",
    "\n",
    "        # Set the vertex properties, not forgetting the id property\n",
    "        data['id'] = str(node)\n",
    "        for key, value in data.items():\n",
    "            gtG.vp[key][v] = value # vp is short for vertex_properties\n",
    "\n",
    "    # Add the edges\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Look up the vertex structs from our vertices mapping and add edge.\n",
    "        e = gtG.add_edge(vertices[src], vertices[dst])\n",
    "\n",
    "        # Add the edge properties\n",
    "        for key, value in data.items():\n",
    "            gtG.ep[key][e] = value # ep is short for edge_properties\n",
    "\n",
    "    # Done, finally!\n",
    "    return gtG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27143fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtG = nx2gt(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    " gtG.list_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e02e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = gt.Graph(gtG)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3175ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58af454",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = fruchterman_reingold_layout(g2, n_iter=1000)\n",
    "graphviz_draw(g2, pos=pos, output=\"graph-draw-fr.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602317c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = gt.draw.arf_layout(gtG, max_iter=0)\n",
    "gt.draw.graphviz_draw(gtG, pos=pos, output=\"graph-draw-arf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93530818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.draw.graphviz_draw(gtG, pos=pos, output=\"graph-draw-arf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265d244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ccd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afa482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916ea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac102f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/usr/lib/python3/dist-packages/graph_tool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
